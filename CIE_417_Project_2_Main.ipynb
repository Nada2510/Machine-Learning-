{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMVse38ebX5z"
      },
      "source": [
        "# Implementing Neural Network from Scratch :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etdaxthQbPv_"
      },
      "source": [
        "* Needed Libraries :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evw9pqzyK2LI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8tBLDG_bzuX"
      },
      "source": [
        "* Defining Activitation function :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgxzUwJEb4Sa"
      },
      "outputs": [],
      "source": [
        "# Activation function (sigmoid)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "# Derivative of sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQAi8pIwcCnh"
      },
      "source": [
        "* Implementing Neurak Network Netwok from scratch using Sigmoid as an activitation function :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94dDdJtDIYw"
      },
      "outputs": [],
      "source": [
        "# Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.rand(self.input_size, self.hidden_size)\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.weights_hidden_output = np.random.rand(self.hidden_size, self.output_size)\n",
        "        self.bias_output = np.zeros((1, self.output_size))\n",
        "#####################################################################################################################\n",
        "    def feedforward(self, X):\n",
        "        # Input to hidden layer\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "        # Hidden to output layer\n",
        "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.predicted_output = sigmoid(self.output_input)\n",
        "\n",
        "        return self.predicted_output\n",
        "#####################################################################################################################\\\n",
        "    def backpropagation(self, X, y, learning_rate):\n",
        "        # Calculate error\n",
        "        output_error = y-self.predicted_output\n",
        "        # Output layer gradient\n",
        "        output_delta = output_error* sigmoid_derivative(self.predicted_output)\n",
        "        # Hidden layer error\n",
        "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "        # Hidden layer gradient\n",
        "        hidden_delta = hidden_error*sigmoid_derivative(self.hidden_output)\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
        "\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "#####################################################################################################################\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            predicted_output = self.feedforward(X)\n",
        "            self.backpropagation(X, y, learning_rate)\n",
        "#####################################################################################################################\n",
        "    def test(self, X_test):\n",
        "        return np.round(self.feedforward(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpcA7nHvUu4b"
      },
      "source": [
        "* Datasets Description :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEbJoYmiU0Vh",
        "outputId": "ab113b83-e9c7-49e2-9ba1-cfdea1151be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Description of IRIS dataset:\n",
            "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count         150.000000        150.000000         150.000000   \n",
            "mean            5.843333          3.057333           3.758000   \n",
            "std             0.828066          0.435866           1.765298   \n",
            "min             4.300000          2.000000           1.000000   \n",
            "25%             5.100000          2.800000           1.600000   \n",
            "50%             5.800000          3.000000           4.350000   \n",
            "75%             6.400000          3.300000           5.100000   \n",
            "max             7.900000          4.400000           6.900000   \n",
            "\n",
            "       petal width (cm)  \n",
            "count        150.000000  \n",
            "mean           1.199333  \n",
            "std            0.762238  \n",
            "min            0.100000  \n",
            "25%            0.300000  \n",
            "50%            1.300000  \n",
            "75%            1.800000  \n",
            "max            2.500000  \n",
            "Information about IRIS dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n",
            "None\n",
            "Statistical Description of MNIST dataset:\n",
            "       pixel_0       pixel_1       pixel_2       pixel_3       pixel_4  \\\n",
            "count   1797.0  1.797000e+03  1.797000e+03  1.797000e+03  1.797000e+03   \n",
            "mean       0.0 -6.326480e-17  7.908099e-17  3.163240e-17 -5.535670e-17   \n",
            "std        0.0  1.000278e+00  1.000278e+00  1.000278e+00  1.000278e+00   \n",
            "min        0.0 -3.350165e-01 -1.094937e+00 -2.786437e+00 -2.764242e+00   \n",
            "25%        0.0 -3.350165e-01 -8.845657e-01 -4.321998e-01 -4.311703e-01   \n",
            "50%        0.0 -3.350165e-01 -2.534522e-01  2.740715e-01  2.687512e-01   \n",
            "75%        0.0 -3.350165e-01  7.984036e-01  7.449191e-01  7.353655e-01   \n",
            "max        0.0  8.485857e+00  2.271002e+00  9.803428e-01  9.686727e-01   \n",
            "\n",
            "            pixel_5      pixel_6       pixel_7       pixel_8       pixel_9  \\\n",
            "count  1.797000e+03  1797.000000  1.797000e+03  1.797000e+03  1.797000e+03   \n",
            "mean  -5.535670e-17     0.000000  1.581620e-17 -2.767835e-17  2.372430e-17   \n",
            "std    1.000278e+00     1.000278  1.000278e+00  1.000278e+00  1.000278e+00   \n",
            "min   -1.020657e+00    -0.409724 -1.250229e-01 -5.907756e-02 -6.240093e-01   \n",
            "25%   -1.020657e+00    -0.409724 -1.250229e-01 -5.907756e-02 -6.240093e-01   \n",
            "50%   -3.145470e-01    -0.409724 -1.250229e-01 -5.907756e-02 -6.240093e-01   \n",
            "75%    9.211453e-01    -0.409724 -1.250229e-01 -5.907756e-02  3.148782e-01   \n",
            "max    1.803783e+00     4.402524  1.433847e+01  2.117340e+01  4.383391e+00   \n",
            "\n",
            "       ...      pixel_54      pixel_55      pixel_56      pixel_57  \\\n",
            "count  ...  1.797000e+03  1.797000e+03  1.797000e+03  1.797000e+03   \n",
            "mean   ... -7.908099e-18  2.372430e-17 -1.186215e-17 -3.954050e-17   \n",
            "std    ...  1.000278e+00  1.000278e+00  1.000278e+00  1.000278e+00   \n",
            "min    ... -7.574358e-01 -2.097851e-01 -2.359646e-02 -2.990813e-01   \n",
            "25%    ... -7.574358e-01 -2.097851e-01 -2.359646e-02 -2.990813e-01   \n",
            "50%    ... -5.541027e-01 -2.097851e-01 -2.359646e-02 -2.990813e-01   \n",
            "75%    ...  6.658963e-01 -2.097851e-01 -2.359646e-02 -2.990813e-01   \n",
            "max    ...  2.495895e+00  1.299989e+01  4.237924e+01  9.336462e+00   \n",
            "\n",
            "           pixel_58      pixel_59      pixel_60      pixel_61      pixel_62  \\\n",
            "count  1.797000e+03  1.797000e+03  1.797000e+03  1.797000e+03  1.797000e+03   \n",
            "mean  -6.326480e-17 -1.818863e-16  4.349455e-17  4.942562e-17  9.885124e-17   \n",
            "std    1.000278e+00  1.000278e+00  1.000278e+00  1.000278e+00  1.000278e+00   \n",
            "min   -1.089383e+00 -2.764171e+00 -2.394110e+00 -1.146647e+00 -5.056698e-01   \n",
            "25%   -8.933661e-01 -2.490095e-01 -3.667712e-01 -1.146647e+00 -5.056698e-01   \n",
            "50%   -3.053152e-01  2.082926e-01  4.441644e-01 -1.295226e-01 -5.056698e-01   \n",
            "75%    8.707865e-01  8.942457e-01  8.496321e-01  8.876023e-01 -1.660165e-02   \n",
            "max    2.046888e+00  8.942457e-01  8.496321e-01  1.565686e+00  3.406875e+00   \n",
            "\n",
            "           pixel_63  \n",
            "count  1.797000e+03  \n",
            "mean   1.581620e-17  \n",
            "std    1.000278e+00  \n",
            "min   -1.960075e-01  \n",
            "25%   -1.960075e-01  \n",
            "50%   -1.960075e-01  \n",
            "75%   -1.960075e-01  \n",
            "max    8.407974e+00  \n",
            "\n",
            "[8 rows x 64 columns]\n",
            "Information about MNIST dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1797 entries, 0 to 1796\n",
            "Data columns (total 64 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   pixel_0   1797 non-null   float64\n",
            " 1   pixel_1   1797 non-null   float64\n",
            " 2   pixel_2   1797 non-null   float64\n",
            " 3   pixel_3   1797 non-null   float64\n",
            " 4   pixel_4   1797 non-null   float64\n",
            " 5   pixel_5   1797 non-null   float64\n",
            " 6   pixel_6   1797 non-null   float64\n",
            " 7   pixel_7   1797 non-null   float64\n",
            " 8   pixel_8   1797 non-null   float64\n",
            " 9   pixel_9   1797 non-null   float64\n",
            " 10  pixel_10  1797 non-null   float64\n",
            " 11  pixel_11  1797 non-null   float64\n",
            " 12  pixel_12  1797 non-null   float64\n",
            " 13  pixel_13  1797 non-null   float64\n",
            " 14  pixel_14  1797 non-null   float64\n",
            " 15  pixel_15  1797 non-null   float64\n",
            " 16  pixel_16  1797 non-null   float64\n",
            " 17  pixel_17  1797 non-null   float64\n",
            " 18  pixel_18  1797 non-null   float64\n",
            " 19  pixel_19  1797 non-null   float64\n",
            " 20  pixel_20  1797 non-null   float64\n",
            " 21  pixel_21  1797 non-null   float64\n",
            " 22  pixel_22  1797 non-null   float64\n",
            " 23  pixel_23  1797 non-null   float64\n",
            " 24  pixel_24  1797 non-null   float64\n",
            " 25  pixel_25  1797 non-null   float64\n",
            " 26  pixel_26  1797 non-null   float64\n",
            " 27  pixel_27  1797 non-null   float64\n",
            " 28  pixel_28  1797 non-null   float64\n",
            " 29  pixel_29  1797 non-null   float64\n",
            " 30  pixel_30  1797 non-null   float64\n",
            " 31  pixel_31  1797 non-null   float64\n",
            " 32  pixel_32  1797 non-null   float64\n",
            " 33  pixel_33  1797 non-null   float64\n",
            " 34  pixel_34  1797 non-null   float64\n",
            " 35  pixel_35  1797 non-null   float64\n",
            " 36  pixel_36  1797 non-null   float64\n",
            " 37  pixel_37  1797 non-null   float64\n",
            " 38  pixel_38  1797 non-null   float64\n",
            " 39  pixel_39  1797 non-null   float64\n",
            " 40  pixel_40  1797 non-null   float64\n",
            " 41  pixel_41  1797 non-null   float64\n",
            " 42  pixel_42  1797 non-null   float64\n",
            " 43  pixel_43  1797 non-null   float64\n",
            " 44  pixel_44  1797 non-null   float64\n",
            " 45  pixel_45  1797 non-null   float64\n",
            " 46  pixel_46  1797 non-null   float64\n",
            " 47  pixel_47  1797 non-null   float64\n",
            " 48  pixel_48  1797 non-null   float64\n",
            " 49  pixel_49  1797 non-null   float64\n",
            " 50  pixel_50  1797 non-null   float64\n",
            " 51  pixel_51  1797 non-null   float64\n",
            " 52  pixel_52  1797 non-null   float64\n",
            " 53  pixel_53  1797 non-null   float64\n",
            " 54  pixel_54  1797 non-null   float64\n",
            " 55  pixel_55  1797 non-null   float64\n",
            " 56  pixel_56  1797 non-null   float64\n",
            " 57  pixel_57  1797 non-null   float64\n",
            " 58  pixel_58  1797 non-null   float64\n",
            " 59  pixel_59  1797 non-null   float64\n",
            " 60  pixel_60  1797 non-null   float64\n",
            " 61  pixel_61  1797 non-null   float64\n",
            " 62  pixel_62  1797 non-null   float64\n",
            " 63  pixel_63  1797 non-null   float64\n",
            "dtypes: float64(64)\n",
            "memory usage: 898.6 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = pd.get_dummies(iris.target).values\n",
        "#####################################################################################################################\n",
        "# Display statistical description for IRIS dataset\n",
        "print(\"Statistical Description of IRIS dataset:\")\n",
        "print(pd.DataFrame(X_iris, columns=iris.feature_names).describe())\n",
        "#####################################################################################################################\n",
        "# Display information about IRIS dataset\n",
        "print(\"Information about IRIS dataset:\")\n",
        "print(pd.DataFrame(X_iris, columns=iris.feature_names).info())\n",
        "#####################################################################################################################\n",
        "# Load MNIST dataset\n",
        "digits = load_digits()\n",
        "X_mnist = StandardScaler().fit_transform(digits.data)\n",
        "y_mnist = pd.get_dummies(digits.target).values\n",
        "#####################################################################################################################\n",
        "# Display statistical description for MNIST dataset\n",
        "print(\"Statistical Description of MNIST dataset:\")\n",
        "print(pd.DataFrame(X_mnist, columns=[f\"pixel_{i}\" for i in range(X_mnist.shape[1])]).describe())\n",
        "#####################################################################################################################\n",
        "# Display information about MNIST dataset\n",
        "print(\"Information about MNIST dataset:\")\n",
        "print(pd.DataFrame(X_mnist, columns=[f\"pixel_{i}\" for i in range(X_mnist.shape[1])]).info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbl7_B4QcArw"
      },
      "source": [
        "* Applying the Neural newtwork and printing the results :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9hp8WmiCfkd",
        "outputId": "e4e358f5-b62c-4ca0-d001-52fac1cac18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (IRIS):\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "Accuracy (IRIS): 100.00%\n",
            "\n",
            "Confusion Matrix (MNIST):\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 1 27  0  0  0  0  0  0  0  0]\n",
            " [ 0  1 31  1  0  0  0  0  0  0]\n",
            " [ 0  0  1 32  0  1  0  0  0  0]\n",
            " [46  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0 44  1  0  0  1]\n",
            " [ 1  0  0  0  0  0 34  0  0  0]\n",
            " [ 1  0  0  0  0  0  0 32  0  1]\n",
            " [ 4  2  0  0  0  1  0  0 23  0]\n",
            " [ 2  0  0  1  0  2  0  0  2 33]]\n",
            "Accuracy (MNIST): 80.28%\n"
          ]
        }
      ],
      "source": [
        "# The results using Sigmoid as an activitation function\n",
        "# Load IRIS dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = pd.get_dummies(iris.target).values\n",
        "#####################################################################################################################\n",
        "# Split the dataset into trai#ning and testing sets\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
        "#####################################################################################################################\n",
        "# Initialize and train the neural network for IRIS dataset\n",
        "input_size_iris = X_iris.shape[1]\n",
        "hidden_size_iris = 10\n",
        "output_size_iris = y_iris.shape[1]\n",
        "epochs_iris = 1000\n",
        "learning_rate_iris = 0.01\n",
        "#####################################################################################################################\n",
        "nn_iris = NeuralNetwork(input_size_iris, hidden_size_iris, output_size_iris)\n",
        "nn_iris.train(X_iris_train, y_iris_train, epochs_iris, learning_rate_iris)\n",
        "#####################################################################################################################\n",
        "# Test the model on IRIS dataset\n",
        "y_iris_pred = nn_iris.test(X_iris_test)\n",
        "conf_matrix_iris = confusion_matrix(np.argmax(y_iris_test, axis=1), np.argmax(y_iris_pred, axis=1))\n",
        "accuracy_iris = accuracy_score(np.argmax(y_iris_test, axis=1), np.argmax(y_iris_pred, axis=1)) * 100\n",
        "#####################################################################################################################\n",
        "print(\"Confusion Matrix (IRIS):\")\n",
        "print(conf_matrix_iris)\n",
        "print(\"Accuracy (IRIS): {:.2f}%\".format(accuracy_iris))\n",
        "#####################################################################################################################\n",
        "# Load MNIST dataset\n",
        "digits = load_digits()\n",
        "X_mnist = StandardScaler().fit_transform(digits.data)\n",
        "y_mnist = pd.get_dummies(digits.target).values\n",
        "#####################################################################################################################\n",
        "# Split the dataset into training and testing sets\n",
        "X_mnist_train, X_mnist_test, y_mnist_train, y_mnist_test = train_test_split(X_mnist, y_mnist, test_size=0.2, random_state=42)\n",
        "#####################################################################################################################\n",
        "# Initialize and train the neural network for MNIST dataset\n",
        "input_size_mnist = X_mnist.shape[1]\n",
        "hidden_size_mnist = 88\n",
        "output_size_mnist = y_mnist.shape[1]\n",
        "epochs_mnist = 1000\n",
        "learning_rate_mnist = 0.01\n",
        "#####################################################################################################################\n",
        "nn_mnist = NeuralNetwork(input_size_mnist, hidden_size_mnist, output_size_mnist)\n",
        "nn_mnist.train(X_mnist_train, y_mnist_train, epochs_mnist, learning_rate_mnist)\n",
        "#####################################################################################################################\n",
        "# Test the model on MNIST dataset\n",
        "y_mnist_pred = nn_mnist.test(X_mnist_test)\n",
        "conf_matrix_mnist = confusion_matrix(np.argmax(y_mnist_test, axis=1), np.argmax(y_mnist_pred, axis=1))\n",
        "accuracy_mnist = accuracy_score(np.argmax(y_mnist_test, axis=1), np.argmax(y_mnist_pred, axis=1)) * 100\n",
        "#####################################################################################################################\n",
        "print(\"\\nConfusion Matrix (MNIST):\")\n",
        "print(conf_matrix_mnist)\n",
        "print(\"Accuracy (MNIST): {:.2f}%\".format(accuracy_mnist))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}